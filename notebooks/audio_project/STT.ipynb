{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpeechToText Project for Darija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas:\n",
    "- Get more data from twitter/facebook etc (ex: DarijaBert)\n",
    "- remove noise background if any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import IPython.display as ipd\n",
    "from datasets import ClassLabel, load_dataset, load_metric\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import Audio, Javascript, display, HTML, Image\n",
    "import torchaudio\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# append path folder where seamless_communication folder has been cloned\n",
    "sys.path.append('/Users/lailasalhi/Documents/AI4Humanitarian/') # to fill\n",
    "\n",
    "import seamless_communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to fill\n",
    "PATH = \"../../data/darija/texts/\"\n",
    "\n",
    "train_df = pd.read_csv(f\"{PATH}/train.csv\", sep='\\t')\n",
    "test_df = pd.read_csv(f'{PATH}/test.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  words\n",
      "0     النار سمعت واحد قال لصاحبه رخص يكون عندنا شويه...\n",
      "1                     مرام راكان اسمع والدلائل شيء واحد\n",
      "2                               ممكن نكون جاي في الطريق\n",
      "3                                       احطه قدام الباب\n",
      "4                     يدك الزخمات اللي طلبنا منك بطاريه\n",
      "...                                                 ...\n",
      "6822                                           مرض مزمن\n",
      "6823                                       ليه خمسه هنا\n",
      "6824           الملح الغير ماده اللي كان بها الشيخ زايد\n",
      "6825  النار سمعت واحد قال لصاحبه رخص يكون عندنا شويه...\n",
      "6826                         قال لنا انا ما بقيت شو اكل\n",
      "\n",
      "[6827 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_df[[\"words\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from fairseq2.models.nllb.tokenizer import NllbTokenizer\n",
    "from m4t_scripts.finetune import dataloader, dist_utils, trainer\n",
    "\n",
    "from seamless_communication.models.unity import (\n",
    "    UnitTokenizer,\n",
    "    UnitYModel,\n",
    "    load_unity_model,\n",
    "    load_unity_text_tokenizer,\n",
    "    load_unity_unit_tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "    text_tokenizer: NllbTokenizer = load_unity_text_tokenizer(args.model_name)\n",
    "    unit_tokenizer: UnitTokenizer = load_unity_unit_tokenizer(args.model_name)\n",
    "    finetune_params = trainer.FinetuneParams(\n",
    "        finetune_mode=args.mode,\n",
    "        save_model_path=args.save_model_to,\n",
    "        device=device,\n",
    "        train_batch_size=args.batch_size,\n",
    "        eval_batch_size=args.batch_size,\n",
    "        patience=args.patience,\n",
    "        max_epochs=args.max_epochs,\n",
    "        learning_rate=args.learning_rate,\n",
    "        warmup_steps=args.warmup_steps,\n",
    "        eval_steps=args.eval_steps,\n",
    "        log_steps=args.log_steps,\n",
    "    )\n",
    "    logger.info(f\"Finetune params: {finetune_params}\")\n",
    "    model: UnitYModel = load_unity_model(\n",
    "        args.model_name, device=finetune_params.device, dtype=torch.float16\n",
    "    )\n",
    "    logger.info(f\"Model {model}\")\n",
    "    assert model.pad_idx == text_tokenizer.vocab_info.pad_idx\n",
    "    assert model.t2u_model is not None\n",
    "    assert model.t2u_model.pad_idx == unit_tokenizer.vocab_info.pad_idx\n",
    "\n",
    "    train_dataloader = dataloader.UnitYDataLoader(\n",
    "        text_tokenizer=text_tokenizer,\n",
    "        unit_tokenizer=unit_tokenizer,\n",
    "        batching_config=dataloader.BatchingConfig(\n",
    "            batch_size=finetune_params.train_batch_size,\n",
    "            rank=dist_utils.get_rank(),\n",
    "            world_size=dist_utils.get_world_size(),\n",
    "        ),\n",
    "        dataset_manifest_path=args.train_dataset,\n",
    "    )\n",
    "    eval_dataloader = dataloader.UnitYDataLoader(\n",
    "        text_tokenizer=text_tokenizer,\n",
    "        unit_tokenizer=unit_tokenizer,\n",
    "        batching_config=dataloader.BatchingConfig(\n",
    "            batch_size=finetune_params.eval_batch_size,\n",
    "            rank=dist_utils.get_rank(),\n",
    "            world_size=dist_utils.get_world_size(),\n",
    "        ),\n",
    "        dataset_manifest_path=args.eval_dataset,\n",
    "    )\n",
    "    finetune = trainer.UnitYFinetune(\n",
    "        model=model,\n",
    "        params=finetune_params,\n",
    "        train_data_loader=train_dataloader,\n",
    "        eval_data_loader=eval_dataloader,\n",
    "    )\n",
    "    finetune.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test of Seamless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seamless_communication.models.inference import Translator\n",
    "\n",
    "# Initialize a Translator object with a multitask model, vocoder on the GPU.\n",
    "translator = Translator(\"seamlessM4T_large\", vocoder_name_or_card=\"vocoder_36langs\", device=torch.device(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test of Seamless with fine tuning on Dvoice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wav2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
